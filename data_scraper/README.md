# Data Scraper - ArbetsfÃ¶rmedlingen Open Data

Denna mapp innehÃ¥ller verktyg fÃ¶r att ladda ner och processa ALLA datasets frÃ¥n ArbetsfÃ¶rmedlingens Ã¶ppna data.

---

## ğŸ“ Struktur

```
data_scraper/
â”œâ”€â”€ download_all_datasets.py    # Main scraper (laddar ner alla datasets)
â”œâ”€â”€ parse_and_normalize.py      # (coming soon) Normaliserar data
â”œâ”€â”€ build_neo4j_graph.py         # (coming soon) Bygger graph database
â””â”€â”€ requirements.txt             # Python dependencies
```

---

## ğŸš€ Quick Start

### 1. Installera dependencies

```bash
cd data_scraper
pip3 install -r requirements.txt
```

### 2. Ladda ner alla datasets

```bash
python3 download_all_datasets.py
```

Detta kommer:
- âœ… Ladda ner 60+ datasets frÃ¥n AF:s API:er
- âœ… Spara dem i `/data/raw/` organiserat per kategori
- âœ… Generera metadata om nedladdningen

**Tid**: ~5-10 minuter (beroende pÃ¥ internet)  
**Storlek**: ~500 MB

---

## ğŸ“Š Vad laddas ner?

### **Kategorier**:

1. **SSYK** - Yrkesklassificering (430 yrken)
2. **SNI** - Branschklassificering (800 branscher)
3. **SUN** - Utbildningsklassificering (400 inriktningar)
4. **Skills** - Kompetenser (8,000 skills)
5. **â­ Relationships** - KRITISKA datasets:
   - SlÃ¤ktskap mellan yrken (career transitions!)
   - NÃ¤rliggande yrken (AI-computed similarities)
   - Relevanta skills per yrke
6. **â­ Forecasts** - Yrkesbarometer (5-Ã¥rs prognoser!)
7. **Education** - SUN-struktur (alla nivÃ¥er)
8. **Geographic** - EU-regioner, lÃ¤nder
9. **Requirements** - KÃ¶rkort, sprÃ¥k, etc.

---

## ğŸ“‚ Output Struktur

Efter nedladdning:

```
data/
â”œâ”€â”€ raw/                          # Original JSON/CSV data
â”‚   â”œâ”€â”€ ssyk/
â”‚   â”‚   â”œâ”€â”€ ssyk-level-1.json
â”‚   â”‚   â”œâ”€â”€ ssyk-level-2.json
â”‚   â”‚   â”œâ”€â”€ ssyk-level-3.json
â”‚   â”‚   â””â”€â”€ ssyk-level-4.json
â”‚   â”œâ”€â”€ sni/
â”‚   â”œâ”€â”€ skills/
â”‚   â”œâ”€â”€ relationships/           # â­ GULD!
â”‚   â”‚   â”œâ”€â”€ occupation-substitutability.json
â”‚   â”‚   â”œâ”€â”€ related-occupations.json
â”‚   â”‚   â””â”€â”€ relevant-skills-for-occupations.json
â”‚   â”œâ”€â”€ forecasts/               # â­ GULD!
â”‚   â”‚   â””â”€â”€ yrkesbarometer.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ processed/                    # (coming soon) Normalized data
â””â”€â”€ download_metadata.json        # Nedladdnings-info
```

---

## ğŸ” Exempel: Inspektera Data

### SSYK Level 4 (alla yrken):

```bash
cat data/raw/ssyk/ssyk-level-4.json | jq '.[0]'
```

Output:
```json
{
  "concept_id": "apaJ_2ja_LuF",
  "preferred_term": "Mjukvaruutvecklare",
  "ssyk_code_2012": "2513",
  "definition": "Utvecklar och underhÃ¥ller mjukvara..."
}
```

### â­ SlÃ¤ktskap mellan yrken:

```bash
cat data/raw/relationships/occupation-substitutability.json | jq '.[0]'
```

Output:
```json
{
  "from_occupation": {
    "concept_id": "xyz",
    "preferred_term": "Butikschef"
  },
  "to_occupation": {
    "concept_id": "abc",
    "preferred_term": "Verksamhetschef"
  },
  "substitutability_level": 75
}
```

**Detta Ã¤r EXAKT vad vi behÃ¶ver fÃ¶r TalentFlow!**

---

## âš ï¸ Important Notes

### API Limits

ArbetsfÃ¶rmedlingens APIs har vissa rate limits:
- Taxonomy API: 1000 requests/hour
- JobSearch API: 100 requests/minute

**VÃ¥r scraper Ã¤r "snÃ¤ll"**:
- 0.5 sekunders delay mellan requests
- Totalt ~60 requests fÃ¶r alla datasets
- Tar ~30 sekunder

### Data Freshness

Olika datasets uppdateras olika ofta:
- **SSYK/SNI/SUN**: Ã…rligen eller kvartalsvis
- **SlÃ¤ktskap/NÃ¤rliggande yrken**: Kvartalsvis
- **Yrkesbarometer**: 2 gÃ¥nger/Ã¥r (vÃ¥r + hÃ¶st)
- **Skills**: Kontinuerligt

**Rekommendation**: KÃ¶r scraper 1 gÃ¥ng/mÃ¥nad fÃ¶r fresh data.

---

## ğŸ”§ Troubleshooting

### "Connection timeout"

```bash
# FÃ¶rsÃ¶k igen, ibland Ã¤r API:et lÃ¥ngsamt
python3 download_all_datasets.py
```

### "Permission denied"

```bash
# Skapa data-mappen manuellt
mkdir -p ../data/raw
python3 download_all_datasets.py
```

### Vissa datasets failar

Detta Ã¤r OK! Inte alla datasets kanske finns tillgÃ¤ngliga via API:et Ã¤n.  
Scrapers Ã¤r byggd fÃ¶r att fortsÃ¤tta Ã¤ven om nÃ¥gra misslyckas.

---

## ğŸ“ Next Steps

Efter nedladdning:

### 1. Analysera schemat

```bash
python3 analyze_schema.py  # (coming soon)
```

### 2. Normalisera datan

```bash
python3 parse_and_normalize.py  # (coming soon)
```

### 3. Bygg graph database

```bash
python3 build_neo4j_graph.py  # (coming soon)
```

---

## ğŸ¤ Contributing

Om du hittar datasets vi missat eller bÃ¤ttre API endpoints:

1. Uppdatera `DATASETS` dictionary i `download_all_datasets.py`
2. KÃ¶r `python3 download_all_datasets.py`
3. Verifiera att datan ser rÃ¤tt ut

---

## ğŸ“š Documentation

FÃ¶r komplett info om datastrukturen, se:
- `/docs/data_structure/COMPLETE_GUIDE.md`
- `/docs/API_RESEARCH.md`

---

**Happy scraping!** ğŸ•·ï¸
